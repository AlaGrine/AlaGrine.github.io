<!DOCTYPE html>
<html lang="en">

<head>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" />

  <!-- Math formulas -->
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>

  <style type="text/css">
    * {
      scroll-behavior: smooth;
    }

    .scrollToTopBtn {
      position: fixed;
      top: 10%;
      left: 50%;
      transform: translate(-50%, -50%);
      padding: 5px 10px;
      background-color: #27ae60;
      color: #fff;
      border-radius: 25px;
      border-radius: 30px solid #fff;
      cursor: pointer;
      transition: all 0.5s ease 0s;
      /* keep it at the top of everything else */
      z-index: 100;
      /* hide with opacity */
      opacity: 0;

    }

    .showBtn {
      opacity: 1;
    }

    /* Rounded border */
    hr.rounded {
      margin-top: 4%;
      margin-bottom: 3%;
      border-top: 5px solid #bbb;
      border-radius: 3px;
    }

    figure.center {
      /* display: flex; */
      align-items: center;
      justify-content: center;
    }

    figure {
      padding: 4px;
      margin: auto;
    }

    figcaption {
      background-color: black;
      color: white;
      font-style: italic;
      padding: 2px;
      text-align: center;
    }
  </style>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <title>Forecasting Bitcoin closing price series | Ala Eddine GRINE</title>
  <meta name="viewport" content="width=device-width,minimum-scale=1">
  <meta name="description" content="Time series forecasting with ARIMA and TensorFlow">
  <meta name="generator" content="Hugo 0.118.2">





  <meta name="robots" content="noindex, nofollow">



  <link rel="stylesheet" href="https://alagrine.github.io/ananke/css/main.min.css">







  <link rel="shortcut icon" href="https://alagrine.github.io/images/portfolio.png" type="image/x-icon" />






  <meta property="og:title" content="Forecasting Bitcoin closing price series" />
  <meta property="og:description" content="Time series forecasting with ARIMA and TensorFlow" />
  <meta property="og:type" content="article" />
  <meta property="og:url" content="https://alagrine.github.io/post/p6-bitcoin_price_forecast/" />
  <meta property="article:section" content="post" />
  <meta property="article:published_time" content="2023-10-20T11:14:48-04:00" />
  <meta property="article:modified_time" content="2023-10-20T11:14:48-04:00" />
  <meta itemprop="name" content="Forecasting Bitcoin closing price series">
  <meta itemprop="description" content="Time series forecasting with ARIMA and TensorFlow">
  <meta itemprop="datePublished" content="2023-10-20T11:14:48-04:00" />
  <meta itemprop="dateModified" content="2023-10-20T11:14:48-04:00" />
  <meta itemprop="wordCount" content="2170">
  <meta itemprop="keywords" content="" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Forecasting Bitcoin closing price series" />
  <meta name="twitter:description" content="Time series forecasting with ARIMA and TensorFlow" />


</head>

<body class="ma0 avenir bg-near-white">






  <header class="cover bg-top" style="background-image: url('https://alagrine.github.io/images/P6/BTC_logo2.jpg');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
        <div class="flex-l justify-between items-center center">
          <a href="https://alagrine.github.io/" class="f3 fw2 hover-white no-underline white-90 dib">

            Ala Eddine GRINE

          </a>
          <div class="flex-l items-center">



            <ul class="pl0 mr3">

              <li class="list f5 f4-ns fw4 dib pr3">
                <a class="hover-white no-underline white-90" href="https://alagrine.github.io/about/"
                  title="About page">
                  About
                </a>
              </li>

              <li class="list f5 f4-ns fw4 dib pr3">
                <a class="hover-white no-underline white-90" href="https://alagrine.github.io/post/"
                  title="Projects page">
                  Projects
                </a>
              </li>

            </ul>


            <div class="ananke-socials">


              <a href="https://github.com/AlaGrine" target="_blank" rel="noopener"
                class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1"
                title="GitHub link" aria-label="follow on GitHub——Opens in a new window">

                <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"
                    xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                    <path
                      d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z" />
                  </svg>
                </span>

                <span class="new-window"><svg height="8px" style="enable-background:new 0 0 1000 1000;" version="1.1"
                    viewBox="0 0 1000 1000" xml:space="preserve" xmlns="http://www.w3.org/2000/svg"
                    xmlns:xlink="http://www.w3.org/1999/xlink">
                    <path
                      d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z"
                      style="fill-rule:evenodd;clip-rule:evenodd;" />
                  </svg>
                </span></a>


              <a href="https://www.linkedin.com/in/ala-eddine-grine" target="_blank" rel="noopener"
                class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1"
                title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">

                <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"
                    xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                    <path
                      d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z"
                      style="fill-rule:evenodd;clip-rule:evenodd;" />
                  </svg>
                </span>

                <span class="new-window"><svg height="8px" style="enable-background:new 0 0 1000 1000;" version="1.1"
                    viewBox="0 0 1000 1000" xml:space="preserve" xmlns="http://www.w3.org/2000/svg"
                    xmlns:xlink="http://www.w3.org/1999/xlink">
                    <path
                      d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z"
                      style="fill-rule:evenodd;clip-rule:evenodd;" />
                  </svg>
                </span></a>


              <a href="https://medium.com/@alaeddine.grine" target="_blank" rel="noopener"
                class="medium ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1"
                title="Medium link" aria-label="follow on Medium——Opens in a new window">

                <span class="icon"><svg style="enable-background:new 0 0 170 170;" version="1.1" viewBox="0 0 170 170"
                    xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                    <path
                      d="M46.5340803,65.2157554 C46.6968378,63.6076572 46.0836,62.018231 44.8828198,60.93592 L32.6512605,46.2010582 L32.6512605,44 L70.6302521,44 L99.9859944,108.380952 L125.794585,44 L162,44 L162,46.2010582 L151.542017,56.2281011 C150.640424,56.9153477 150.193188,58.0448862 150.380019,59.1628454 L150.380019,132.837155 C150.193188,133.955114 150.640424,135.084652 151.542017,135.771899 L161.755369,145.798942 L161.755369,148 L110.38282,148 L110.38282,145.798942 L120.963119,135.527337 C122.002801,134.487948 122.002801,134.182246 122.002801,132.592593 L122.002801,73.0417402 L92.585901,147.755438 L88.6106443,147.755438 L54.3622782,73.0417402 L54.3622782,123.115814 C54.0767278,125.221069 54.7759199,127.3406 56.2581699,128.863022 L70.0186741,145.55438 L70.0186741,147.755438 L31,147.755438 L31,145.55438 L44.7605042,128.863022 C46.2319621,127.338076 46.8903838,125.204485 46.5340803,123.115814 L46.5340803,65.2157554 Z"
                      style="fill-rule:evenodd;clip-rule:evenodd;" />
                  </svg>
                </span>

                <span class="new-window"><svg height="8px" style="enable-background:new 0 0 1000 1000;" version="1.1"
                    viewBox="0 0 1000 1000" xml:space="preserve" xmlns="http://www.w3.org/2000/svg"
                    xmlns:xlink="http://www.w3.org/1999/xlink">
                    <path
                      d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z"
                      style="fill-rule:evenodd;clip-rule:evenodd;" />
                  </svg>
                </span></a>

            </div>

          </div>
        </div>
      </nav>

      <div class="tc-l pv6 ph3 ph4-ns">

        <div class="f2 f1-l fw2 white-90 mb0 lh-title">Forecasting Bitcoin closing price series</div>

        <div class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">
          Time series forecasting
        </div>


      </div>
    </div>
  </header>



  <main class="pb7" role="main">


    <article class="flex-l flex-wrap justify-between mw8 center ph3">
      <header class="mt4 w-100">
        <aside class="instapaper_ignoref b helvetica tracked">

          PROJECTS
        </aside>











        <div id="sharing" class="mt3 ananke-socials">


          <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://alagrine.github.io/post/p6-bitcoin_price_forecast/&amp;title=Forecasting%20Bitcoin%20closing%20price%20series"
            class="ananke-social-link linkedin no-underline" aria-label="share on LinkedIn">

            <span class="icon"> <svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"
                xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                <path
                  d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z"
                  style="fill-rule:evenodd;clip-rule:evenodd;" />
              </svg>
            </span>

          </a>

        </div>


        <h1 class="f1 athelas mt3 mb1">Forecasting Bitcoin closing price series</h1>



        <time class="f6 mv4 dib tracked" datetime="2023-10-20T11:14:48-04:00">October 20, 2023</time>




      </header>
      <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-100">
        <h1 id="project-overview">Project Overview:</h1>
        <p>Time series forecasting is one of the most widely used data science techniques in business and finance to
          make future strategic decisions.</p>
        <p>In this project, we will be forecasting a series of daily closing prices for
          <a href="https://coinmarketcap.com/currencies/bitcoin/">Bitcoin</a>, a peer-to-peer online currency, based on
          its historical prices.
        </p>
        <p>We will follow different approaches to time series forecasting, implementing both statistical techniques
          and machine learning algorithms.</p>
        <p>We will start by building an <code>ARIMA</code> (AutoRegressive Integrated Moving Average) model, one of the
          most widely
          used approaches to time series forecasting.</p>
        <p>We will then use <code>Tensorflow</code> to build several artificial neural networks, including Dense, Long
          Short-Term
          Memory (LSTM) and 1D Convolutional Neural Network.</p>
        <p>We will then step things up by building the N-BEATS algorithm with Tensorflow and <code>DARTS</code>.</p>
        <p>Finally, we will leverage the <code>tsfresh</code> package to automatically extract and select time series
          features.</p>


        <div class="mb-4">
          <hr class="rounded">
        </div>

        <h1 id="time-series-analysis">Time Series analysis</h1>
        <p>Here is the evolution of the Bitcoin closing price over time:</p>
        <figure><img src="https://alagrine.github.io/images/P6/1-price.png" />
        </figure>

        <p>At the beginning (from 2015 to February 2017), the upward trend is almost absent. Thereafter, the
          frequency
          and amplitude of the cycle appear to change over time. This suggests that the model is multiplicative.</p>
        <p>As our series is a non-seasonal data, we will restrict our attention to non-seasonal <code>ARIMA</code>
          models.</p>
        <p>To confirm these observations, let&rsquo;s take a look at the <strong>ACF</strong> of our time series.
        </p>
        <br>
        <br>
        <h2 id="acf-autocorrelation-function">ACF (Autocorrelation Function)</h2>
        <p>Autocorrelation measures the linear relationship between lagged values of a time series. The
          relationship
          between \(y_{t}\) and \(y_{t-k}\) can be written as:</p>
        <p>$$ r_k = {\displaystyle\sum\limits_{t=k+1}^{T} (y_t-\bar y) (y_{t-k}-\bar y) \over
          \displaystyle\sum\limits_{t=1}^{T} (y_t-\bar y)^2} $$</p>
        <p>where <strong>T</strong> is is the length of the time series and \(\bar y\) is its mean. The
          autocorrelation
          function or ACF is made up of the autocorrelation coefficients. <br>
          It can be calculated using the <a
            href="https://www.statsmodels.org/stable/generated/statsmodels.tsa.stattools.acf.html">ACF()</a>
          function
          from <code>statsmodels.tsa.stattools</code>.</p>
        <p>For white noise series, we expect each autocorrelation to be close to zero and 95% of the spikes in the
          ACF
          to lie within <strong>± 1.96/\(\sqrt{T}\)</strong>.</p>
        <p>If one or more large spikes are outside these bounds, then the series is probably not white noise.</p>
        <p>To display the autocorrelation coefficients, we can use the <a
            href="https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html">plot_acf</a>
          function from <em> statsmodels.graphics.tsaplots</em> or <a
            href="https://pandas.pydata.org/docs/reference/api/pandas.plotting.autocorrelation_plot.html">autocorrelation_plot</a>
          from <em>pandas.plotting</em>. But for better visibility, we will create our own
          <code>plot_xACF_plotly</code> function using <a href="https://plotly.com/python/">Plotly</a> as follows:
        </p>
        <script type="application/javascript"
          src="https://gist.github.com/AlaGrine/2e943d9aef8dc13ebf441d10b74e80ea.js"></script>

        <p>The graph below shows:</p>
        <ul>
          <li> This is a typical ACF of a trended time series characterised by a strong autocorrelation between the
            current price and the closest previous observations, and a linear slow decrease as the lags increase.
          </li>
          <li>There are no seasonal lags. </li>
        </ul>

        <figure><img src="https://alagrine.github.io/images/P6/2-ACF.png" />
        </figure>

        <div class="mb-4">
          <hr class="rounded">
        </div>

        <h1 id="bitcoin-price-forecasting-with-arima-using-pmdarima">Bitcoin price forecasting with ARIMA using
          pmdarima
        </h1>
        <p>ARIMA is an acronym for AutoRegressive Integrated Moving Average.</p>
        <p>The ARIMA(p,d,q) model includes both lagged values of \(y_t\) (AR part) and
          lagged errors \(\epsilon_{t}\) (MA part) and can be written as follows:</p>
        <p>$$ \acute{y}_t = c + {\displaystyle\sum\limits_{i=1}^{p} \phi_{i} \acute{y}_{t-i} +
          \displaystyle\sum\limits_{j=1}^{q} \theta_{j} \epsilon_{t-j} + \epsilon_{t} }$$</p>
        <p>where:</p>
        <ul>
          <li><strong>\(\acute{y}_t\)</strong> is the differenced series (d-order difference, d&gt;=1).</li>
          <li><strong>p</strong> = The order of the autoregressive (AR);</li>
          <li><strong>d</strong> = The degree of the differencing;</li>
          <li><strong>q</strong> = The order of the moving average (MA) model.</li>
        </ul>
        <p>The parameters <strong>p</strong> and <strong>q</strong> can be iteratively searched-for with the
          <code>auto_arima</code> function.
        </p>
        <p>Tests of stationarity (like <em>ADF</em> or <em>KPSS</em>) are required to estimate the the
          differencing
          term, <strong>d</strong>.</p>
        <br>
        <h2 id="train_test_split">Train_test_split</h2>
        <p>Instead of a traditional random train/test split, we will split our dataset (bitcoin_prices) into
          <strong>sequential</strong> train and test subsets to have a dataset that reflects the past (train set)
          and
          a
          dataset that reflects the future (test set).
        </p>
        <p>We can create an arbitrary point in time to split our data.
          Everything before that point can be considered the training set and everything after is the test set.
        </p>
        <p>We&rsquo;ll be using the training set (the past) to train a model that will try to predict values on
          the
          test
          set (the future).</p>
        <script type="application/javascript"
          src="https://gist.github.com/AlaGrine/2ce75d725bde1d96e4abedaed82b21c8.js"></script>
        <br>
        <h2 id="differencing-d">Differencing (d)</h2>
        <p>To address the non-stationarity of our series, we will take a first difference of the data.
          <script type="application/javascript"
            src="https://gist.github.com/AlaGrine/c6044537d736e695bf6c44a31319ab82.js"></script>
        </p>
        <p>Auto-correlation plots are an easy way to determine whether our time series is sufficiently
          stationary
          for
          modeling.</p>
        <p>Let&rsquo;s check the ACF of the differences series.</p>
        <figure><img src="https://alagrine.github.io/images/P6/3-ACF-diff1.png" />
        </figure>

        <p>The autocorrelation plot of the <em>differences series</em> appears relatively stationary. It shows
          no
          significant relationship between the lagged observations (all correlations are small and close to
          zero).
          Thus,
          the parameter <strong>d</strong> is likely to be 1.</p>
        <br>
        <h2 id="tests-of-stationarity">Tests of stationarity</h2>
        <p>To determine more quantitatively whether we need to difference our data to make it stationary, and
          to
          estimate the number of differences, we can run a test of stationarity (either <em>ADF Test</em>,
          <em>PP
            Test</em> or <em>KPSS Test</em>).
        </p>
        <script type="application/javascript"
          src="https://gist.github.com/AlaGrine/12c85cc32ba8a359ccae5df753675069.js"></script>

        <p>Tests show that one difference (ie, d=1) suffices to make our series stationary.</p>
        <br>
        <h2 id="use-acf-and-pacf-plots-to-determine-appropriate-values-for-p-and-q">Use ACF and PACF plots to
          determine
          appropriate values for p and q</h2>
        <p>ACF and PACF can soetimes helps to guess the paremeters (p and q) of the ARIMA model.</p>
        <p>Partial autocorrelations measure the relationship between \(y_{t}\) and \(y_{t-k}\) after
          removing the
          effects of lags 1,2,3,..k.</p>
        <p>They have the same critical values of <strong>± 1.96/\(\sqrt{T}\)</strong> as for ordinary
          autocorrelations.
        </p>
        <figure><img src="https://alagrine.github.io/images/P6/4-PACF-diff1.png" />
        </figure>

        <p>Since there is no significant spike at lag <strong>p</strong> in the ACF and PACF plots of the
          differenced
          data, it is not possible to detremine (simply from these plots) whether the data are from an
          ARIMA(p,d,0)
          or
          an ARIMA(0,d,q).</p>
        <p>In the next section, we will use the <code>auto_arima</code> process from pmdarima to
          automatically
          identify
          the most optimal parameters for an ARIMA(p,d,q) model.</p>
        <br>
        <h2 id="auto_arima">Auto_arima</h2>
        <script type="application/javascript"
          src="https://gist.github.com/AlaGrine/e9d4abc3833776a5239061f1f9b8709d.js"></script>

        <p>The auto_arima function performed a full or a stepwise search through various combinations of
          the p, d,
          and
          q
          parameters of ARIMA and selects the parameters that minimize the <strong>AIC</strong> value
          (Akaike&rsquo;s
          Information Criterion).</p>
        <p>The summary displays the AIC values and estimated model parameters for each candidate model
          that was
          evaluated:</p>
        <ul>
          <li>The automated stepwise selection has identified an <strong>ARIMA(1,1,0)</strong> model,
            which has
            the
            lowest AIC value and no intercept.</li>
          <li>The full search (stepwise=False) has found that an <strong>ARIMA(0,1,4)</strong> gives the
            lowest
            AIC
            value, with an intercept of 16.1521.</li>
        </ul>
        <br>
        <h2 id="residual-diagnostics">Residual diagnostics</h2>
        <p>It is important to check that the residuals are uncorrelated, so that no information is left
          in the
          residuals, and that they have a mean of zero, so that the forecasts are not biased.</p>
        <pre tabindex="0"><code>ARIMA_residuals = ARIMA_model.resid()
</code></pre>
        <p>
        <figure><img src="https://alagrine.github.io/images/P6/5_residuals_ARIMA.png" />
        </figure>

        <figure><img src="https://alagrine.github.io/images/P6/6_residuals_hist_ARIMA.png" />
        </figure>

        <figure><img src="https://alagrine.github.io/images/P6/7_residuals_ACF_ARIMA.png" />
        </figure>
        </p>
        <p>The ACF plot of the residuals from the ARIMA(0,1,4) model shows that the residuals are
          uncorrelated, so
          there
          is no information left in the residuals that should be used to compute forecasts.</p>
        <p>As the mean is not zero, then the forecasts are biased. To handle this, we can add 17.334 to
          all
          forecasts
          and the bias problem is solved.</p>
        <br>
        <h2 id="predictions">Predictions</h2>
        <p>Our ARIMA model has be trained using the y_train dataset.</p>
        <p>To evaluate our model, we will compare our predictions to y_test (the test set).</p>
        <p>As explained <a href="https://alkaline-ml.com/pmdarima/refreshing.html">here</a>, we can
          update our ARIMA model with only new observations (in our case, prices from y_test dataset), so that future
          forecasts take the latest observations into account. This allows us to keep our ARIMA model updated without
          having to completely refitting it.</p>
        <script type="application/javascript"
          src="https://gist.github.com/AlaGrine/6052f08aa7f944d8b629cd8b3cb5058b.js"></script>

        <p>The next graph shows both point predictions and confidence intervals (light orange area). The former
          represent the most likely values according to the model, while the latter give us a measure of uncertainty.
        </p>

        <figure><img src="https://alagrine.github.io/images/P6/8_predictions_ARIMA.png" />
        </figure>

        <p>Our ARIMA predictions seem to follow the data well. When we zoom in, we see that they come slightly after the
          test data.</p>
        <p>Each prediction in the ARIMA(0,1,4) forecast is off by an average of $527.7, which is 2% of the mean Bitcoin
          price.</p>
        <p>In the next section, we are going to be using TensorFlow to build deep learning models to try and improve on
          our ARIMA forecasting results.</p>

        <div class="mb-4">
          <hr class="rounded">
        </div>

        <h1 id="bitcoin-price-forecasting-with-deep-learning-models-using-tensorflow">Bitcoin price forecasting with
          deep learning models using Tensorflow
        </h1>
        <p>We will be building a variety of deep learning models (including Dense, CNN and RNN models). These models
          will make predictions based on a <strong>window</strong> of successive or lagged values of the data.
        </p>
        <blockquote>
          <p>A deep learning model with <strong>p</strong> lagged inputs and <strong>0</strong> nodes in
            the hidden layer is equivalent to an ARIMA(p,0,0).</p>
        </blockquote>
        <br>
        <h2 id="windowing">Windowing</h2>
        <p>Windowing is used to turn a time series dataset into <em>supervised learning problem</em>.
        </p>
        <p>We need to set two hyperparameters:</p>
        <ul>
          <li><code>HORIZON</code> = number of timesteps to predict into future;</li>
          <li><code>WINDOW_SIZE</code> = number of timesteps or lags from past used to predict
            HORIZON.</li>
        </ul>
        <p>For example, with a horizon of 1 and a window size of 7, we can predict the price of BTC
          for tomorrow based on the prices of the previous week.</p>
        <p>We can use the <a
            href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shift.html">pandas.DataFrame.shift()</a>
          method to create a windowed time series, as follows:</p>
        <script type="application/javascript"
          src="https://gist.github.com/AlaGrine/decfb154bb051b6a5920a4697ef8785a.js"></script>

        <br>
        <h2 id="make-a-multivariate-time-series">Make a multivariate time series</h2>
        <p>In addition to the lagged values of the BTC price, we can use other features related to
          Bitcoin, such as the the <a href="https://www.investopedia.com/terms/b/block-reward.asp">Bitcoin block reward
            size</a>, which is the number of Bitcoin awarded for mining a Bitcoin block.</p>
        <p>The block reward size is halved after the creation of every 210,000 blocks (ie. 1% of
          bitcoins). It went from 50 in January 2009 to 25 in November 2012 and 6.25 in May 2020.</p>
        <blockquote>
          <p>By adding an extra feature to our dataset, such as the size of the Bitcoin block
            reward, our data goes from <strong>univariate</strong> (only the historical price of bitcoin) to
            <strong>multivariate</strong> (the price of Bitcoin and the size of the block reward).
          </p>
        </blockquote>
        <figure><img src="https://alagrine.github.io/images/P6/9-block-reward.png" />
        </figure>
        <br>
        <h2 id="modelling-and-evaluation">Modelling and Evaluation</h2>
        <p>We will be building the following model structure:</p>
        <pre tabindex="0"><code>Input (windowed dataset) -&gt; Custom_Layers -&gt; Output (BTC price)
</code></pre>
        <p>The main component we&rsquo;ll be changing throughout is the <code>Custom_Layers</code>
          component. More specifically, we will build the following:</p>
        <ul>
          <li><strong>Model 1</strong>: A simple Dense model</li>
          <li><strong>Model 2</strong>: LSTM model</li>
          <li><strong>Model 3</strong>: GRU model</li>
          <li><strong>Model 4</strong>: 1D Convolutional Neural Network</li>
        </ul>
        <p>Each model are built using the following function:</p>
        <script type="application/javascript"
          src="https://gist.github.com/AlaGrine/25980c4f7a49fae7e8f79cc6737df879.js"></script>

        <p>For example, to create a <code>Dense</code> model, the following layers are used:</p>
        <pre tabindex="0"><code>Dense_layers = [layers.Dense(128,activation=&#34;relu&#34;)]
</code></pre>
        <figure><img src="https://alagrine.github.io/images/P6/10-MAE-per-WindowSize.png" />
        </figure>

        <p>Clearly, the smaller the window size, the better the MAE. The optimal window size for
          all models is <strong>1</strong>. This means that the best performance is obtained by replicating the
          <strong>Naïve</strong> model.
        </p>
        <p>For window sizes greater than 1, the Dense model yields the best results.</p>

        <div class="mb-4">
          <hr class="rounded">
        </div>
        <h1 id="n-beats-algorithm-with-tensorflow">N-BEATS algorithm with Tensorflow
        </h1>
        <p>So far, we have been building our models with only few layers.</p>
        <p>In this section, we will step things up by replicating the the generic version
          of <a href="https://arxiv.org/pdf/1905.10437.pdf">N-BEATS (Neural Basis Expansion Analysis
            for Interpretable Time Series Forecasting) algorithm</a>, which focuses on univariate time series problems
          and achieved state-of-the-art performance.
        </p>
        <p>The <code>N-BEATS</code> architecture is deep, yet very simple as shown in the
          following figure:
        </p>
        <figure>
          <img src="https://alagrine.github.io/images/P6/NBETAS_architecture.png" style="width:100%" />
          <figcaption>N-BEATS architecture <a href="https://arxiv.org/pdf/1905.10437.pdf">source</a></figcaption>
        </figure>
        <br>



        <p>There are 3 main components:</p>
        <ol>
          <li><strong>Block layer:</strong> it&rsquo;s composed of 4 Dense layers. It predicts the
            expansion
            coefficients \(\theta^f\), the forecast, and \(\theta^b\) the backcast.</li>
          <li><strong>Stack layer:</strong> Blocks are organized into stacks using doubly residual
            architecture,
            which
            can be described as follows:
            $$ X_{k+1} = { (X_{k}-\hat X_{k}) , \hat Y = \displaystyle\sum\limits_{k} \hat Y_k }$$
            <ul>
              <li>The model subtracts \(\hat X_{k}\), the backcast signal, from \(X_k\) the input
                signal to block k.
              </li>
              <li>The final forecast, \(\hat Y\), is the sum of all forecast \(\hat Y_k\) signals from
                all blocks.
              </li>
            </ul>
          </li>
          <li>Stack layers are also stacked, further increasing the depth of the model and its
            ability to learn complex time series.</li>
        </ol>
        <script type="application/javascript"
          src="https://gist.github.com/AlaGrine/d13f20aaf9075a218ed969a16b253b88.js"></script>

        <p>Despite its deep architecture, the results of the NBEATS model are similar to those of the simple Dense
          model (with an MAE of around 528 for a Window size of 1).</p>

        <div class="mb-4">
          <hr class="rounded">
        </div>
        <h1 id="n-beats-algorithm-with-darts">N-BEATS algorithm with DARTS</h1>
        <p>In the previous section, we have built the N-BEATS algorithm from the scratch using Tensorflow.</p>
        <p>In this section, we will use <a href="https://unit8co.github.io/darts/README.html">DARTS</a> (Data Analytics
          and Real-Time Systems) to automatically build the N-BEATS algorithm and make <a
            href="https://unit8co.github.io/darts/userguide/forecasting_overview.html#probabilistic-forecasts">probabilistic
            forecasts</a> (ie. with CI intervals).</p>
        <p>The code snippet below shows the steps we&rsquo;ll go through, from building the DARTS time series to making
          historical forecasts and confidence intervals.</p>
        <script type="application/javascript"
          src="https://gist.github.com/AlaGrine/d342ce51f9f899ba128b3eb11ec57249.js"></script>

        <div class="mb-4">
          <hr class="rounded">
        </div>
        <h1 id="bitcoin-price-forecasting-with-tsfresh">Bitcoin price forecasting with Tsfresh
        </h1>
        <p>So far, we have built ARIMA and deep learning models. These models use lagged values of
          the data to predict the BTC price.</p>
        <p>We have found that the best results are obtained with a window size (or lag) of 1. This
          means that they basically replicate what a Naïve model would do, simply predicting the previous time
          step value for the next value.</p>
        <p>In this section, we will be leveraging <a href="https://tsfresh.readthedocs.io/en/latest/">Tsfresh</a>
          (<em>Time Series Feature extraction based on scalable hypothesis tests</em>), an
          open-source Python package that automatically calculates hundreds of time series features and assists
          in feature selection.</p>
        <br>
        <h2 id="feature-extraction-with-tsfresh">Feature extraction with tsfresh</h2>
        <p>Feature engineering with tsfresh is very simple.</p>
        <script type="application/javascript"
          src="https://gist.github.com/AlaGrine/8155c95b100e7d480e4fe31a529a0f4e.js"></script>

        <p>The <code>extract_features</code> method returned <strong>783</strong> time-series
          features (including min, max, standard deviation, etc.).</p>
        <p>To narrow down this list, we can use the <code>select_features</code> method to
          remove all NaN values and select only the relevant features. In our case, we are left with 164
          relevant features.
        </p>
        <br>
        <h2 id="modelling">Modelling</h2>
        <p>Now that we have selected relevant features, we can leverage any regression model from sklearn.
        </p>
        <p>We will use ElasticNetCV.</p>
        <pre tabindex="0"><code>from sklearn.linear_model import ElasticNetCV
ElasticNetCV_model = ElasticNetCV(l1_ratio=[.1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99, 1])

# 1. Fit the data to the model
ElasticNetCV_model.fit(X_train_scaled, y_train)

# 2. Evaluate the model
preds = ElasticNetCV_model.predict(X_test_scaled)
metrics_ElasticNetCV = evaluate_model(y_test, preds,&#34;ElasticNetCV_and_tsfresh&#34;)
</code></pre>
        <p>With ElasticNetCV, and using the relevant features returned by tsfresh, the MAE is
          around
          <strong>429</strong>. This is much better than what we got with the ARIMA and Tensorflow models.
        </p>
        <p>The most important features of the model are shown in the graph below.</p>
        <figure><img src="https://alagrine.github.io/images/P6/11_most_important_features.png" />
        </figure>

        <div class="mb-4">
          <hr class="rounded">
        </div>

        <h1 id="forecast-bitcoins-price-into-the-future-with-full-historical-data">Forecast Bitcoin&rsquo;s price into
          the future with full historical data</h1>
        <p>Previously, we split our data into training and test sets to evaluate our models on pseudo-future data (the
          test set).</p>
        <p>Now, we will fit our models to the full historical data to make a one step forecast.</p>
        <br>
        <h2 id="forecasts-with-arima-and-univariate-data">Forecasts with ARIMA and univariate data</h2>
        <p>Fitting the ARIMA model to the full data yields the following results:</p>
        <ul>
          <li>The full search (stepwise=False) has found that an ARIMA(2,1,2) gives the lowest AIC value, with an
            intercept of 15.936.</li>
          <li>The automated stepwise selection has identified an ARIMA(0,1,0) model, equivalent to a random walk.</li>
        </ul>
        <p>We will make forecasts with ARIMA(2,1,2).</p>
        <blockquote>
          <p>Note that for each forecast, we will update our ARIMA model with this new prediction using the
            <code>update</code> function.
          </p>
        </blockquote>
        <figure><img src="https://alagrine.github.io/images/P6/12-ARIMA-forecasts.png" />
        </figure>

        <p>The plot shows that the mean forecasts look very similar to what we would get with a random walk (equivalent
          to an ARIMA(0,1,0)). Including AR and MA terms (p=2 and q=2) has made little difference to the point
          forecasts.</p>
        <br>
        <h2 id="forecasts-with-a-multivariate-dense-model-using-tensorflow">Forecasts with a multivariate Dense model
          using Tensorflow</h2>
        <p>We will use a multivariate data (the price of Bitcoin and the size of the block reward).</p>
        <p>Our forecasting process is as follows:</p>
        <ol>
          <li>Make a one step forecast (one timestep into the future)</li>
          <li>Retrain our model with this new prediction</li>
          <li>Appended the new prediction to the data,</li>
          <li>Make a prediction, append the prediction, retrain a model&hellip; etc.</li>
        </ol>
        <figure><img src="https://alagrine.github.io/images/P6/13-Dense-Forecasts.png" />
        </figure>

        <p>Here the last observation (Window size =1) and the block reward are used as predictors and there are 128
          neurons in the hidden Dense layer.</p>


        <div class="mb-4">
          <hr class="rounded">
        </div>
        <h1 id="conclusion">Conclusion
        </h1>
        <p>In this project, I have been forecasting a series of daily closing prices for
          Bitcoin.
        </p>
        <p>I built a variety of models, from classics such as <strong>ARIMA</strong> to deep
          neural networks using the
          historical price of Bitcoin.</p>
        <p>I found that these models basically replicate the Naïve model, which simply
          predicts the previous time step value for the next value. This goes to show how hard it is to beat the Naïve
          model in open systems such as stock or crypto markets.</p>
        <p>Finally, I harnessed the power of <strong>tsfresh</strong> to extract and select
          time series features. Using relevant features with ElasticNetCV (in fact, we could use any regression model
          from sklearn) yielded the best results with an MAE of 429 compared to 528 for the previous models.</p>


        <p>Throughout this project, I have used several time series libraries, namely
          <a href="https://tsfresh.readthedocs.io/en/latest">tsfresh</a>,
          <a href="https://unit8co.github.io/darts/README.html">DARTS</a> and
          <a href="http://alkaline-ml.com/pmdarima">pmdarima</a>.
        </p>
        <p>There are other libraries, we can levarage, such as
          <a href="https://www.sktime.net/en/stable">sktime</a>,
          <a href="https://facebook.github.io/prophet/docs/quick_start.html#python-api">prophet</a> and
          <a href="https://linkedin.github.io/greykite/">greykite</a> to name a few.
        </p>



        <br>
        <p><a href="https://github.com/AlaGrine/Toxic-Comment-Classification-with-Tensorflow">Link
            to GitHub repository</a></p>


        <span class="badge badge-pill badge-success">Time series analysis</span>
        <span class="badge badge-pill badge-success">ARIMA</span>
        <span class="badge badge-pill badge-success">Tesnsorflow</span>
        <span class="badge badge-pill badge-success">Tsfresh</span>

        <ul class="pa0">

        </ul>
        <div class="mt6 instapaper_ignoref">


        </div>
      </div>

      <aside class="w-30-l mt6-l">
      </aside>

    </article>




  </main>



  <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
    <div class="flex justify-between">
      <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://alagrine.github.io/">
        &copy; Ala Eddine GRINE 2023
      </a>
      <div>
        <div class="ananke-socials">


          <a href="https://github.com/AlaGrine" target="_blank" rel="noopener"
            class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1"
            title="GitHub link" aria-label="follow on GitHub——Opens in a new window">

            <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"
                xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                <path
                  d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z" />
              </svg>
            </span>

            <span class="new-window"><svg height="8px" style="enable-background:new 0 0 1000 1000;" version="1.1"
                viewBox="0 0 1000 1000" xml:space="preserve" xmlns="http://www.w3.org/2000/svg"
                xmlns:xlink="http://www.w3.org/1999/xlink">
                <path
                  d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z"
                  style="fill-rule:evenodd;clip-rule:evenodd;" />
              </svg>
            </span></a>


          <a href="https://www.linkedin.com/in/ala-eddine-grine" target="_blank" rel="noopener"
            class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1"
            title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">

            <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"
                xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                <path
                  d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z"
                  style="fill-rule:evenodd;clip-rule:evenodd;" />
              </svg>
            </span>

            <span class="new-window"><svg height="8px" style="enable-background:new 0 0 1000 1000;" version="1.1"
                viewBox="0 0 1000 1000" xml:space="preserve" xmlns="http://www.w3.org/2000/svg"
                xmlns:xlink="http://www.w3.org/1999/xlink">
                <path
                  d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z"
                  style="fill-rule:evenodd;clip-rule:evenodd;" />
              </svg>
            </span></a>


          <a href="https://medium.com/@alaeddine.grine" target="_blank" rel="noopener"
            class="medium ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1"
            title="Medium link" aria-label="follow on Medium——Opens in a new window">

            <span class="icon"><svg style="enable-background:new 0 0 170 170;" version="1.1" viewBox="0 0 170 170"
                xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
                <path
                  d="M46.5340803,65.2157554 C46.6968378,63.6076572 46.0836,62.018231 44.8828198,60.93592 L32.6512605,46.2010582 L32.6512605,44 L70.6302521,44 L99.9859944,108.380952 L125.794585,44 L162,44 L162,46.2010582 L151.542017,56.2281011 C150.640424,56.9153477 150.193188,58.0448862 150.380019,59.1628454 L150.380019,132.837155 C150.193188,133.955114 150.640424,135.084652 151.542017,135.771899 L161.755369,145.798942 L161.755369,148 L110.38282,148 L110.38282,145.798942 L120.963119,135.527337 C122.002801,134.487948 122.002801,134.182246 122.002801,132.592593 L122.002801,73.0417402 L92.585901,147.755438 L88.6106443,147.755438 L54.3622782,73.0417402 L54.3622782,123.115814 C54.0767278,125.221069 54.7759199,127.3406 56.2581699,128.863022 L70.0186741,145.55438 L70.0186741,147.755438 L31,147.755438 L31,145.55438 L44.7605042,128.863022 C46.2319621,127.338076 46.8903838,125.204485 46.5340803,123.115814 L46.5340803,65.2157554 Z"
                  style="fill-rule:evenodd;clip-rule:evenodd;" />
              </svg>
            </span>

            <span class="new-window"><svg height="8px" style="enable-background:new 0 0 1000 1000;" version="1.1"
                viewBox="0 0 1000 1000" xml:space="preserve" xmlns="http://www.w3.org/2000/svg"
                xmlns:xlink="http://www.w3.org/1999/xlink">
                <path
                  d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z"
                  style="fill-rule:evenodd;clip-rule:evenodd;" />
              </svg>
            </span></a>

        </div>
      </div>
    </div>
  </footer>


  <!-- Add ScrollToTop button; only visible when we scroll up -->
  <div id="scrollToTopBtn" class="scrollToTopBtn"> <i class="fas fa-arrow-up"></i> Back to
    top</div>

  <script>

    window.onscroll = function () {
      if (pageYOffset >= 200) {
        document.getElementById('scrollToTopBtn').style.visibility = "visible";
      } else {
        document.getElementById('scrollToTopBtn').style.visibility = "hidden";
      }
    };
    var scrollToTopBtn = document.querySelector(".scrollToTopBtn");
    var rootElement = document.documentElement;

    let lastScrollTop = window.pageYOffset || document.documentElement.scrollTop;

    function handleScroll() {
      var scrollTotal = rootElement.scrollHeight - rootElement.clientHeight;
      const scrollTopPosition = window.pageYOffset || document.documentElement.scrollTop;

      if (scrollTopPosition > lastScrollTop) {
        // Hide button
        scrollToTopBtn.classList.remove("showBtn");
      } else if (scrollTopPosition < lastScrollTop) {
        // Show button
        scrollToTopBtn.classList.add("showBtn");
      }
      lastScrollTop = scrollTopPosition <= 0 ? 0 : scrollTopPosition;
    }

    function scrollToTop() {
      rootElement.scrollTo({
        top: 0,
        behavior: "smooth"
      });
      handleScroll();
    }
    scrollToTopBtn.addEventListener("click", scrollToTop);
    document.addEventListener("scroll", handleScroll);
  </script>


</body>

</html>