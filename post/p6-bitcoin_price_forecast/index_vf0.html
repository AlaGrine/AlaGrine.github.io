<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Forecasting Bitcoin closing price series | Ala Eddine GRINE</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Time series forecasting with TensorFlow">
    <meta name="generator" content="Hugo 0.118.2">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="https://alagrine.github.io/ananke/css/main.min.css" >



    
    
    
      
<link rel="shortcut icon" href="https://alagrine.github.io/images/portfolio.png" type="image/x-icon" />


    

    
    
    <meta property="og:title" content="Forecasting Bitcoin closing price series" />
<meta property="og:description" content="Time series forecasting with TensorFlow" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://alagrine.github.io/post/p6-bitcoin_price_forecast/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-10-20T11:14:48-04:00" />
<meta property="article:modified_time" content="2023-10-20T11:14:48-04:00" />
<meta itemprop="name" content="Forecasting Bitcoin closing price series">
<meta itemprop="description" content="Time series forecasting with TensorFlow"><meta itemprop="datePublished" content="2023-10-20T11:14:48-04:00" />
<meta itemprop="dateModified" content="2023-10-20T11:14:48-04:00" />
<meta itemprop="wordCount" content="2101">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Forecasting Bitcoin closing price series"/>
<meta name="twitter:description" content="Time series forecasting with TensorFlow"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  <header class="cover bg-top" style="background-image: url('https://alagrine.github.io/images/P6/BTC_logo.png');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://alagrine.github.io/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Ala Eddine GRINE
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://alagrine.github.io/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://alagrine.github.io/post/" title="Projects page">
              Projects
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
    
    <a href="https://github.com/AlaGrine" target="_blank" rel="noopener" class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="https://www.linkedin.com/in/ala-eddine-grine" target="_blank" rel="noopener" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="https://medium.com/@alaeddine.grine" target="_blank" rel="noopener" class="medium ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Medium link" aria-label="follow on Medium——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 170 170;" version="1.1" viewBox="0 0 170 170"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M46.5340803,65.2157554 C46.6968378,63.6076572 46.0836,62.018231 44.8828198,60.93592 L32.6512605,46.2010582 L32.6512605,44 L70.6302521,44 L99.9859944,108.380952 L125.794585,44 L162,44 L162,46.2010582 L151.542017,56.2281011 C150.640424,56.9153477 150.193188,58.0448862 150.380019,59.1628454 L150.380019,132.837155 C150.193188,133.955114 150.640424,135.084652 151.542017,135.771899 L161.755369,145.798942 L161.755369,148 L110.38282,148 L110.38282,145.798942 L120.963119,135.527337 C122.002801,134.487948 122.002801,134.182246 122.002801,132.592593 L122.002801,73.0417402 L92.585901,147.755438 L88.6106443,147.755438 L54.3622782,73.0417402 L54.3622782,123.115814 C54.0767278,125.221069 54.7759199,127.3406 56.2581699,128.863022 L70.0186741,145.55438 L70.0186741,147.755438 L31,147.755438 L31,145.55438 L44.7605042,128.863022 C46.2319621,127.338076 46.8903838,125.204485 46.5340803,123.115814 L46.5340803,65.2157554 Z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <div class="f2 f1-l fw2 white-90 mb0 lh-title">Forecasting Bitcoin closing price series</div>
          
            <div class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">
              Time series forecasting with TensorFlow
            </div>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        PROJECTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
      
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://alagrine.github.io/post/p6-bitcoin_price_forecast/&amp;title=Forecasting%20Bitcoin%20closing%20price%20series" class="ananke-social-link linkedin no-underline" aria-label="share on LinkedIn">
        
        <span class="icon"> <svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
        
      </a>
    
  </div>


      <h1 class="f1 athelas mt3 mb1">Forecasting Bitcoin closing price series</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2023-10-20T11:14:48-04:00">October 20, 2023</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-100"><h2 id="project-overview">Project Overview:</h2>
<p>Time series analysis is widely used to identify patterns and trends that can be used to predict the future.</p>
<p>In this article I forecast daily closing price series of <a href="https://coinmarketcap.com/currencies/bitcoin/">Bitcoin</a>, a peer-to-peer online currency, using the historical price of Bitcoin and volumes of the previous days.</p>
<p>I followed different approaches to time series forecasting, implementing both statistical techniques and machine learning algorithms.</p>
<p>I started by using ARIMA (AutoRegressive Integrated Moving Average), one of the most widely used approaches to time series forecat.</p>
<p>I then leveraged 3 Python libraries to handle this time series problem: tsfresh, autots, darts, atspy, kats, sktime, prophet, greykite.</p>
<p>Finally, I used Tensorflow to build several artificial neural networks: Multilayer Perceptron (MLP) and Long Short-Term Memory (LSTM) and NBEATS.</p>
<h2 id="time-series-analysis">Time Series analysis</h2>
<figure><img src="https://alagrine.github.io/images/P6/1-price.png"/>
</figure>

<p>At the beginning (from 2015 to 2017-02), the upward trend is almost absent; in later years, the frequency and amplitude of the cycle appear to change over time. This suggests that the model is multiplicative.</p>
<p>As our series is a non-seasonal data, we will restrict our attention to non-seasonal <code>ARIMA</code> models.</p>
<h3 id="acf-autocorrelation-function">ACF (Autocorrelation Function)</h3>
<p>Autocorrelation measures the linear relationship between lagged values of a time series. The relationship between  \(y_{t}\) and \(y_{t-k}\) can be written as:</p>
<p>$$ r_k = {\displaystyle\sum\limits_{t=k+1}^{T}  (y_t-\bar y) (y_{t-k}-\bar y)   \over   \displaystyle\sum\limits_{t=1}^{T} (y_t-\bar y)^2} $$</p>
<p>where <strong>T</strong> is is the length of the time series and \(\bar y\) is its mean. The autocorrelation function or ACF is made up of the autocorrelation coefficients. <br>
It can be calculated using the <a href="https://www.statsmodels.org/stable/generated/statsmodels.tsa.stattools.acf.html">ACF()</a> function from <code>statsmodels.tsa.stattools</code>.</p>
<p>For white noise series, we expect each autocorrelation to be close to zero and 95% of the spikes in the ACF to lie within  <strong>± 1.96/\(\sqrt{T}\)</strong>.</p>
<p>If one or more large spikes are outside these bounds, then the series is probably not white noise.</p>
<p>To display the autocorrelation coefficients, we can use the <a href="https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html">plot_acf</a> function from <code>statsmodels.graphics.tsaplots</code> or <a href="https://pandas.pydata.org/docs/reference/api/pandas.plotting.autocorrelation_plot.html">autocorrelation_plot</a> from <code>pandas.plotting</code>. But for better visibility, we will create our own <code>plot_xACF_plotly</code> function using <a href="https://plotly.com/python/">Plotly</a> as follows:</p>
<script type="application/javascript" src="https://gist.github.com/AlaGrine/2e943d9aef8dc13ebf441d10b74e80ea.js"></script>

<p>The graph above shows a strong autocorrelation between the current price and the closest previous observations, and a linear slowly decrease from there to the first 2200 lagged values.</p>
<figure><img src="https://alagrine.github.io/images/P6/2-ACF.png"/>
</figure>

<h2 id="arima-model-with-pmdarima">ARIMA model with pmdarima</h2>
<p>ARIMA is an acronym for AutoRegressive Integrated Moving Average. <em>Integrated</em> is the differencing we saw in the previous section. The ARIMA(p,d,q) model includes both lagged values of \(y_t\) (AR part) and lagged errors \(\epsilon_{t}\) (MA part) and can be written as follows:</p>
<p>$$ \acute{y}<em>t = c + {\displaystyle\sum\limits</em>{i=1}^{p}  \phi_{i} \acute{y}<em>{t-i}  + \displaystyle\sum\limits</em>{j=1}^{q} \theta_{j} \epsilon_{t-j}  +  \epsilon_{t} }$$</p>
<p>where:</p>
<ul>
<li><strong>\(\acute{y}_t\)</strong> is the differenced series (d-order difference, d&gt;=1).</li>
<li><strong>p</strong> = The order of the autoregressive (AR);</li>
<li><strong>d</strong> = The degree of the differencing;</li>
<li><strong>q</strong> = The order of the moving average (MA) model.</li>
</ul>
<p>The parameters <strong>p</strong> and <strong>q</strong> can be iteratively searched-for with the <code>auto_arima</code> function.</p>
<p>Tests of stationarity (like <em>ADF</em> or <em>KPSS</em>) are required to estimate the the differencing term, <strong>d</strong>.</p>
<h3 id="train_test_split">Train_test_split</h3>
<p>Let&rsquo;s first split our dataset (bitcoin_prices) into <strong>sequential</strong> train and test subsets.</p>
<script type="application/javascript" src="https://gist.github.com/AlaGrine/2ce75d725bde1d96e4abedaed82b21c8.js"></script>

<h3 id="differencing-d">Differencing (d)</h3>
<p>To address the non-stationarity of our series, we will take a first difference of the data.
<script type="application/javascript" src="https://gist.github.com/AlaGrine/c6044537d736e695bf6c44a31319ab82.js"></script>
</p>
<p>Auto-correlation plots are an easy way to determine whether our time series is sufficiently stationary for modeling.</p>
<p>Let&rsquo;s check the ACF of the differences series.</p>
<figure><img src="https://alagrine.github.io/images/P6/3-ACF-diff1.png"/>
</figure>

<p>The autocorrelation plot of the <em>differences series</em> appears relatively stationary. It shows no significant relationship between the lagged observations (all correlations are small and close to zero). Thus, the parameter <strong>d</strong> is likely to be 1.</p>
<h3 id="tests-of-stationarity">Tests of stationarity</h3>
<p>To determine more quantitatively whether we need to difference our data to make it stationary, and to estimate the number of differences, we can run a test of stationarity (either <em>ADF Test</em>, <em>PP Test</em> or <em>KPSS Test</em>).</p>
<script type="application/javascript" src="https://gist.github.com/AlaGrine/12c85cc32ba8a359ccae5df753675069.js"></script>

<p>Tests show that one difference (ie, d=1) suffices to make our series stationary.</p>
<h3 id="use-acf-and-pacf-plots-to-determine-appropriate-values-for-p-and-q">Use ACF and PACF plots to determine appropriate values for p and q</h3>
<p>ACF and PACF can soetimes helps to guess the paremeters (p and q) of the ARIMA model.</p>
<p>Partial autocorrelations measure the relationship between \(y_{t}\) and \(y_{t-k}\) after removing the effects of lags 1,2,3,..k.</p>
<p>They have the same critical values of <strong>± 1.96/\(\sqrt{T}\)</strong> as for ordinary autocorrelations.</p>
<figure><img src="https://alagrine.github.io/images/P6/4-PACF-diff1.png"/>
</figure>

<p>Since there is no significant spike at lag <strong>p</strong> in the ACF and PACF plots of the differenced data, it is not possible to detremine (simply from these plots) whether the data are from an ARIMA(p,d,0) or an ARIMA(0,d,q).</p>
<p>In the next section, we will use the <code>auto_arima</code> process from pmdarima to automatically identify the most optimal parameters for an ARIMA(p,d,q) model.</p>
<h3 id="auto_arima">Auto_arima</h3>
<script type="application/javascript" src="https://gist.github.com/AlaGrine/e9d4abc3833776a5239061f1f9b8709d.js"></script>

<p>The auto_arima function performed a full or a stepwise search through various combinations of the p, d, and q parameters of ARIMA and selects the parameters that minimize the <strong>AIC</strong> value (Akaike&rsquo;s Information Criterion).</p>
<p>The summary displays the AIC values and estimated model parameters for each candidate model that was evaluated:</p>
<ul>
<li>The automated stepwise selection has identified an <strong>ARIMA(1,1,0)</strong> model, which has the lowest AIC value and no intercept.</li>
<li>The full search (stepwise=False) has found that an <strong>ARIMA(0,1,4)</strong> gives the lowest AIC value, with an intercept of 16.1521.</li>
</ul>
<h3 id="residual-diagnostics">Residual diagnostics</h3>
<p>It is important to check that the residuals are uncorrelated, so that no information is left in the residuals, and that they have a mean of zero, so that the forecasts are not biased.</p>
<pre tabindex="0"><code>ARIMA_residuals = ARIMA_model.resid()
</code></pre><p><figure><img src="https://alagrine.github.io/images/P6/5_residuals_ARIMA.png"/>
</figure>

<figure><img src="https://alagrine.github.io/images/P6/6_residuals_hist_ARIMA.png"/>
</figure>

<figure><img src="https://alagrine.github.io/images/P6/7_residuals_ACF_ARIMA.png"/>
</figure>
</p>
<p>The ACF plot of the residuals from the ARIMA(0,1,4) model shows that the residuals are uncorrelated, so there is no information left in the residuals that should be used to compute forecasts.</p>
<p>As the mean is not zero, then the forecasts are biased. To handle this, we can add 17.334 to all forecasts and the bias problem is solved.</p>
<h3 id="predictions">Predictions</h3>
<p>Our ARIMA model has be trained using the y_train dataset.</p>
<p>To evaluate our model, we will compare our predictions to y_test, the test set which is a pseudofuture and not the actual future.</p>
<p>As explained <a href="https://alkaline-ml.com/pmdarima/refreshing.html">here</a>, we can update our ARIMA model with only new observations (in our case, prices from y_test dataset), so that future forecasts take the latest observations into account. This allows us to keep our ARIMA model updated without having to completely refitting it.</p>
<script type="application/javascript" src="https://gist.github.com/AlaGrine/6052f08aa7f944d8b629cd8b3cb5058b.js"></script>

<figure><img src="https://alagrine.github.io/images/P6/8_predictions_ARIMA.png"/>
</figure>

<p>Our ARIMA predictions seem to follow the data well. When we zoom in, we see that they come slightly after the test data.</p>
<p>On average each ARIMA forecast is ~$567 different than the actual Bitcoin price.</p>
<p>The average price of Bitcoin in the test dataset is: $27,042.
Each prediction in the ARIMA(0,1,4) forecast is off by an average of $527.7, which is 2% of the mean.</p>
<p>In the next section, we are going to be using TensorFlow to build deep learning models to try and improve on our ARIMA forecasting results.</p>
<p>There are many other kinds of models we are going to look into for performing forecasts.</p>
<p>Some of them may even beat our best performing models in this notebook.</p>
<p>The Pearson correlation analysis presented below also confirms that there is no correlation between text length and labels.</p>
<figure><img src="https://alagrine.github.io/images/P5/fig3.png"/>
</figure>

<p>The heatmap shows that there is a strong correlation between the terms <em><code>toxic</code></em>, <em><code>insulting</code></em> and <em><code>obscene</code></em>. Therefore, if a comment has one of these three labels, it is likely to have the others as well.</p>
<h3 id="wordcloud">Wordcloud</h3>
<figure><img src="https://alagrine.github.io/images/P5/wordcloud.png"/>
</figure>

<p>The wordcloud above shows the most common words used in comments. At first glance, it looks respectful and related to online discussions.</p>
<p>However, when we filter out the toxic comments, the most frequent terms become extremely profane, vulgar and offensive, so I prefer not to show them here.<br>
Another takeaway is that there is a significant difference in the top 10 toxic words between the different labels. This analysis can be found in this Jupyter <a href="https://github.com/AlaGrine/Toxic-Comment-Classification-with-Tensorflow/blob/main/Toxic-Comment-Classification-with-Tensorflow.ipynb">notebook</a>.</p>
<h2 id="handling-unbalanced-dataset">Handling unbalanced dataset</h2>
<p>To deal with this unbalanced dataset, I:</p>
<ol>
<li>
<p>Used <code>stratified data split</code> instead of the traditional train_test_split.<br>
I leveraged the <a href="http://scikit.ml/api/skmultilearn.model_selection.iterative_stratification.html">iterative stratification for multi-label data</a> from the <code>scikit-multilearn</code> library.</p>
</li>
<li>
<p>Performed <code>text data augmentation</code> to increase the number of minority labels (namely &rsquo;threat&rsquo; and &lsquo;identity_hate&rsquo;).<br>
I used the <a href="https://pypi.org/project/googletrans/">googletrans</a> API to translate the given comment into French, German and Spanish and then back into English (back-translation). In this way we get new sentences with similar meanings, thus increasing the number of the minority labels.</p>
</li>
</ol>
<script type="application/javascript" src="https://gist.github.com/AlaGrine/5a7e796ebb329404cdad5ba107faa4f1.js"></script>

<ol start="3">
<li>Built a <code>custom binary cross-entropy loss function with class weights</code>.<br>
The weights are inversely proportional to the number of samples in each class, so that the minority labels are given a greater weight.</li>
</ol>
<script type="application/javascript" src="https://gist.github.com/AlaGrine/9f433a55b4bb0dcaedb2be7784729d9c.js"></script>

<ol start="4">
<li>Used the <strong>precision</strong>, <strong>recall</strong> and <strong>AUC</strong> as evaluation metrics instead of the accuracy.<br>
If the model always predicts <strong>0</strong> (ie. a non toxic comment), we get a good accuracy of 90%. However, this hides the true performance of the classifier, which never identifies a toxic comment. Accuracy is therefore misleading and should not be used here.</li>
</ol>
<h2 id="text-preprocessing-textvectorization-and-embedding">Text Preprocessing, TextVectorization and Embedding</h2>
<p>First, I leveraged the <a href="https://www.nltk.org/">NLTK</a> package to clean the messages. Punctuation, special characters and stop words were removed.</p>
<script type="application/javascript" src="https://gist.github.com/AlaGrine/b30735322c2f4cc99009abc4c59927aa.js"></script>

<p>I then used TensorFlow&rsquo;s <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization">TextVectorization</a> layer to turn the text into numbers by mapping each word to a unique index. I kept all the parameters default for this layer except for:</p>
<ul>
<li><em><strong>Max_tokens</strong></em>: the number of unique words in our dataset, which I set to <strong>153K</strong>.</li>
<li><em><strong>Output_sequence_length</strong></em>: the output length for each vectorized message, which I set to <strong>118</strong> since 95% of the cleaned messages are less than 118 words.</li>
</ul>
<p>Finally, to better represent the relationships between tokens in our corpus, I created a trainable <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding">Embedding</a> layer that is updated during training. It maps each word index to a dense vector representation with a shape (Output_sequence_length,128), where <strong>128</strong> is the output dimension of the dense embedding.</p>
<script type="application/javascript" src="https://gist.github.com/AlaGrine/a736ba0f580ee5edaa4544440ce1da48.js"></script>

<h2 id="modelling">Modelling</h2>
<p>I used <code>Tensorflow</code> to build the following model structure:</p>
<pre tabindex="0"><code>Input (text) -&gt; TextVectorization -&gt; Embedding -&gt; Custom_Layers -&gt; Output (sigmoid)
</code></pre><p>The main component I changed throughout is the <code>Custom_Layers</code> component. More specifically, I built the following:</p>
<ul>
<li><strong>Model 1</strong>: A simple Dense model</li>
<li><strong>Model 2</strong>: LSTM model</li>
<li><strong>Model 3</strong>: GRU model</li>
<li><strong>Model 4</strong>: 1D Convolutional Neural Network</li>
</ul>
<p>The <em>Output</em> layer is a dense layer that returns the probability of each label. As this it a multi-label classification problem, the <em>sigmoid</em> activation function was used here.</p>
<p>A threshold of 0.5 was applied to convert the probabilities into binary predictions (0 or 1).</p>
<pre tabindex="0"><code>preds = np.array(probs &gt; 0.5, dtype=int)
</code></pre><p>To ensure that we don&rsquo;t reuse trained embeddings (and thus avoid data leakage between models), I created a new <code>Embedding</code> layer for each model. <br>
I reused the <code>TextVectorisation</code> layer as it is not updated during training.</p>
<p>Each model was built using the following function:</p>
<script type="application/javascript" src="https://gist.github.com/AlaGrine/29d4c90f9cb5b915446a08953560a65e.js"></script>

<p>For example, to create a <code>Dense</code> model, I called this function and passed the following layers as a parameter:</p>
<pre tabindex="0"><code>Dense_layers = [layers.Dense(32,activation=&#34;relu&#34;),
                layers.Flatten(),
                layers.Dropout(0.5)]
</code></pre><p>To create a <code>Bidirectional LSTM</code> model, the following layers were used:</p>
<pre tabindex="0"><code>LSTM_layers = [layers.Bidirectional(layers.LSTM(32,activation=&#34;tanh&#34;)),
               layers.Dropout(0.2),
               layers.Dense(16,activation=&#34;relu&#34;),
               layers.Dropout(0.2)]
</code></pre><p>The LSTM layer has 32 units and uses the hyperbolic tangent (tanh) activation function.</p>
<h2 id="results-and-interpretation">Results and Interpretation</h2>
<p>To evaluate the model, <strong>AUC</strong> (Area Under the Curve), <strong>precision</strong> and <strong>recall</strong> metrics were used.</p>
<figure><img src="https://alagrine.github.io/images/P5/AUC_dense__model.png"/>
</figure>

<p>As shown above, using the custom binary cross-entropy loss function with class weights, and performing text data augmentation (using the googletrans API) resulted in a <strong>4%</strong> increase in AUC for the Dense model.</p>
<p>Both techniques were then applied to the other models that I trained for 5 epochs.</p>
<figure><img src="https://alagrine.github.io/images/P5/AUC_perModel.png"/>
</figure>

<p>As we can see, the <em>GRU</em> model performed best with an AUC of <strong>97.7%</strong>, <strong>0.3%</strong> ahead of the <em>LSTM</em> model.</p>
<p>Now let&rsquo;s take a look at precision and recall.</p>
<figure><img src="https://alagrine.github.io/images/P5/fig5.png"/>
</figure>

<p>When data augmentation and custom loss (<em>BinaryCrossentropy with class weights</em>) were used, recall jumped to over 95% for all labels. With the default loss function (<em>BinaryCrossentropy</em>), it was around 0.01% for <em>threat</em> and <em>identity_hate</em>.<br>
The increase in recall came at the cost of precision, as shown in the next table. In fact, while we tried not to miss any of the toxic comments (positive class), many negative samples were allowed, leading to a decrease in precision.</p>
<figure><img src="https://alagrine.github.io/images/P5/fig4.png"/>
</figure>

<h2 id="possible-improvements">Possible improvements</h2>
<p>So far, we have been building our own embedding layer from scratch.</p>
<p>To improve our models, we could try different configurations, such as adding more layers or adjusting the number of neurons per layer.</p>
<p>Another alternative is to take advantage of <code>Transfer Learning</code> and use a pre-trained embedding layer, such as <a href="https://tfhub.dev/google/collections/bert/1">BERT</a> available on the TensorFlow Hub.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In this project, I built several neural network based models for toxic comment classification using Tensorflow. They were first trained on a cleaned and augmented text data leveraging the <em>NLTK</em> and <em>googletrans</em> APIs, and then evaluated using the <em>AUC</em>, <em>recall</em> and <em>precision</em> metrics.</p>
<p>I demonstrated how to deal with class imbalance using several techniques, including stratified data splitting, data augmentation, and creating a custom loss function with class weights.</p>
<p>A good performance was achieved with the <em>GRU</em> model with an AUC of 97.7%.</p>
<p><a href="https://github.com/AlaGrine/Toxic-Comment-Classification-with-Tensorflow">Link to GitHub repository</a></p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://alagrine.github.io/" >
    &copy;  Ala Eddine GRINE 2023 
  </a>
    <div>
<div class="ananke-socials">
  
    
    <a href="https://github.com/AlaGrine" target="_blank" rel="noopener" class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="https://www.linkedin.com/in/ala-eddine-grine" target="_blank" rel="noopener" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="https://medium.com/@alaeddine.grine" target="_blank" rel="noopener" class="medium ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Medium link" aria-label="follow on Medium——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 170 170;" version="1.1" viewBox="0 0 170 170"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M46.5340803,65.2157554 C46.6968378,63.6076572 46.0836,62.018231 44.8828198,60.93592 L32.6512605,46.2010582 L32.6512605,44 L70.6302521,44 L99.9859944,108.380952 L125.794585,44 L162,44 L162,46.2010582 L151.542017,56.2281011 C150.640424,56.9153477 150.193188,58.0448862 150.380019,59.1628454 L150.380019,132.837155 C150.193188,133.955114 150.640424,135.084652 151.542017,135.771899 L161.755369,145.798942 L161.755369,148 L110.38282,148 L110.38282,145.798942 L120.963119,135.527337 C122.002801,134.487948 122.002801,134.182246 122.002801,132.592593 L122.002801,73.0417402 L92.585901,147.755438 L88.6106443,147.755438 L54.3622782,73.0417402 L54.3622782,123.115814 C54.0767278,125.221069 54.7759199,127.3406 56.2581699,128.863022 L70.0186741,145.55438 L70.0186741,147.755438 L31,147.755438 L31,145.55438 L44.7605042,128.863022 C46.2319621,127.338076 46.8903838,125.204485 46.5340803,123.115814 L46.5340803,65.2157554 Z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
